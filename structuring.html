<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
    <!-- Replace the content tag with appropriate information -->
    <meta name="description" content="Structuring Radiology Reports: Challenging LLMs with Lightweight Models">
    <meta property="og:title" content="SRR"/>
    <meta property="og:description" content="Structuring Radiology Reports: Challenging LLMs with Lightweight Models"/>
    <meta property="og:url" content="URL OF THE WEBSITE"/>
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
    <meta property="og:image" content=""/>
    <meta property="og:image:width" content="1200"/>
    <meta property="og:image:height" content="630"/>


    <meta name="twitter:title" content="">
    <meta name="twitter:description" content="">
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
    <meta name="twitter:card" content="">
    <!-- Keywords for your paper to be indexed by-->
    <meta name="keywords" content="Radiology Report Generation, LLM, Evaluation">
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <title>Structuring Radiology Reports: <br>Challenging LLMs with Lightweight Models</title>
    <link rel="icon" type="image/x-icon" href="src/static-chexagent/images/favicon.png">
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="src/static-chexagent/css/bulma.min.css">
    <link rel="stylesheet" href="src/static-chexagent/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="src/static-chexagent/css/bulma-slider.min.css">
    <link rel="stylesheet" href="src/static-chexagent/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="src/static-chexagent/css/index.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
    <script defer src="src/static-chexagent/js/fontawesome.all.min.js"></script>
    <script src="src/static-chexagent/js/bulma-carousel.min.js"></script>
    <script src="src/static-chexagent/js/bulma-slider.min.js"></script>
    <script src="src/static-chexagent/js/index.js"></script>
</head>
<body>


<section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <h1 class="title is-1 publication-title">Structuring Radiology Reports: Challenging LLMs with Lightweight Models</h1>
                    <div class="is-size-5 publication-authors">
                        <!-- Paper authors -->
    <!-- Paper authors -->
<span class="author-block"><a href="https://github.com/johannes2moll" target="_blank">Johannes Moll</a><sup>1,2</sup>,</span>
<span class="author-block"><a href="https://www.medizin.uni-tuebingen.de/de/das-klinikum/mitarbeiter/profil/4361" target="_blank">Louisa Fay</a><sup>1</sup>,</span>
<span class="author-block"><a href="https://langlotzlab.stanford.edu/people/asfandyar-azhar" target="_blank">Asfandyar Azhar</a><sup>1,3</sup>,</span>
<span class="author-block"><a href="https://scholar.google.com/citations?user=Q2SCA-sAAAAJ&hl=en" target="_blank">Sophie Ostmeier</a><sup>1</sup>,</span>

<span class="author-block"><a href="https://www.professoren.tum.de/lueth-tim-c/" target="_blank">Tim Lueth</a><sup>2</sup>,</span>
<span class="author-block"><a href="https://med.stanford.edu/profiles/sergios-gatidis" target="_blank">Sergios Gatidis</a><sup>1</sup>,</span>
<span class="author-block"><a href="https://profiles.stanford.edu/curtis-langlotz" target="_blank">Curtis Langlotz</a><sup>1</sup>,</span>
<span class="author-block"><a href="https://jbdel.github.io/" target="_blank">Jean-Benoit Delbrouck</a><sup>1,4</sup></span>

                    </div>

                    <div class="is-size-5 publication-authors">
                        <span class="author-block"><sup>1</sup>Stanford AIMI &nbsp;&nbsp;|&nbsp;&nbsp; <sup>2</sup>Technical University of Munich&nbsp;&nbsp;|&nbsp;&nbsp;<sup>3</sup>Carnegie Mellon University&nbsp;&nbsp;|&nbsp;&nbsp;<sup>4</sup>HOPPR</span>
                    </div>

                    <div class="column has-text-centered">
                        <div class="publication-links">
                            <!-- ArXiv abstract Link -->
                            <span class="link-block">
                                <a href="http://arxiv.org/abs/2506.00200" target="_blank"
                                   class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon">
                                        <i class="ai ai-arxiv"></i>
                                    </span>
                                    <span>arXiv</span>
                                </a>
                            </span>

                            <!-- Github link -->
                            <span class="link-block">
                                <a href="https://github.com/jomoll/rad-report-structuring" target="_blank"
                                   class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon">
                                        <i class="fab fa-github"></i>
                                    </span>
                                    <span>Code</span>
                                </a>
                            </span>

                            <!-- HuggingFace link -->
                            <span class="link-block">
                                <a href="https://huggingface.co/StanfordAIMI" target="_blank"
                                   class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon">
                                        <i class="fas fa-smile"></i>
                                    </span>
                                    <span>HuggingFace</span>
                                </a>
                            </span>

                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>


<!-- Paper abstract -->
<section class="section hero is-light">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Abstract</h2>
                <div class="content has-text-justified">
                    <p>
                        Radiology reports are critical for clinical decision-making but often lack a standardized format, limiting both human interpretability and machine learning (ML) applications. While large language models (LLMs) have shown strong capabilities in reformatting clinical text, their high computational requirements, lack of transparency, and data privacy concerns hinder practical deployment. To address these challenges, we explore lightweight encoder-decoder models (<300M parameters)—specifically T5 and BERT2BERT—for structuring radiology reports from the MIMIC-CXR and CheXpert Plus datasets. We benchmark these models against eight open-source LLMs (1B–70B parameters), adapted using prefix prompting, in-context learning (ICL), and low-rank adaptation (LoRA) finetuning. Our best-performing lightweight model outperforms all LLMs adapted using prompt-based techniques on a human-annotated test set. While some LoRA-finetuned LLMs achieve modest gains over the lightweight model on the Findings section (BLEU 6.4%, ROUGE-L 4.8%, BERTScore 3.6%, F1-RadGraph 1.1%, GREEN 3.6%, and F1-SRR-BERT 4.3%), these improvements come at the cost of substantially greater computational resources. For example, LLaMA-3-70B incurred more than 400 times the inference time, cost, and carbon emissions compared to the lightweight model. These results underscore the potential of lightweight, task-specific models as sustainable and privacy-preserving solutions for structuring clinical text in resource-constrained healthcare settings.                        <figure>
                        <img src="src/static-structuring/generation2.png" width="100%" alt="Overview" class="center-image blend-img-background">
                    </figure>
                </div>
            </div>
        </div>
    </div>
</section>
<!-- End paper abstract -->

<!-- Models -->
<section class="section hero">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Lightweight Models</h2>
                <div class="content has-text-justified">
                    <p>
                        <table style="width:100%; border-collapse: collapse; text-align: left; font-family: Arial, sans-serif;">
                            <thead>
                              <tr>
                                <th style="padding: 10px; font-weight: bold; vertical-align: middle;">Model</th>
                                <th style="padding: 10px; font-weight: bold; vertical-align: middle;">HuggingFace Link</th>
                              </tr>
                            <tbody>
                              <!-- BERT2BERT -->
                              <tr>
                                <td rowspan="4" style="padding: 10px; font-weight: bold; vertical-align: middle;">BERT2BERT</td>
                                <td style="padding: 10px;">
                                  <a href="https://huggingface.co/StanfordAIMI/SRR-BERT2BERT-RoBERTa-base" target="_blank">
                                    🤗 StanfordAIMI/SRR-BERT2BERT-RoBERTa-base
                                  </a>
                                </td>
                                <td style="padding: 10px;">
                                  <a href="https://huggingface.co/StanfordAIMI/SRR-BERT2BERT-RoBERTa-biomed" target="_blank">
                                    🤗 StanfordAIMI/SRR-BERT2BERT-RoBERTa-biomed
                                  </a>
                                </td>
                                <td style="padding: 10px;">
                                  <a href="https://huggingface.co/StanfordAIMI/SRR-BERT2BERT-RoBERTa-PM-M3" target="_blank">
                                    🤗 StanfordAIMI/SRR-BERT2BERT-RoBERTa-PM-M3
                                  </a>
                                </td>
                                <td style="padding: 10px;">
                                  <a href="https://huggingface.co/StanfordAIMI/SRR-BERT2BERT-RadBERT" target="_blank">
                                    🤗 StanfordAIMI/SRR-BERT2BERT-RadBERT
                                  </a>
                                </td>
                              </tr>
                            </tbody>
                          </table>
                          
                    </p>
                </div>
            </div>
        </div>
    </div>
</section>
<!-- End Models -->

<!-- Paper results -->
<section class="section hero is-light">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Results</h2>
                <div class="content has-text-justified">
                    <p>
                        We benchmarked our best lightweight model against open-source LLMs (1B–70B parameters), adapted using prefix prompting, in-context learning (ICL), and low-rank adaptation (LoRA) finetuning. The results are summarized in the figure below:
                    </p>
                    <figure>
                        <img src="src/static-structuring/benchmark.png" width="100%" alt="Results" class="center-image blend-img-background">
                    </figure>
                </div>
            </div>
        </div>
    </div>

<!--BibTex citation -->
<section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
        <h2 class="title">BibTeX</h2>
        <pre><code>@article{TBD}
          
</code></pre>
    </div>
</section>
<!--End BibTex citation -->


<footer class="footer">
    <div class="container">
        <div class="columns is-centered">
            <div class="column is-8">
                <div class="content">
                    <p>
                        Last update: 2024/05. Template credited to <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>.
                    </p>
                </div>
            </div>
        </div>
    </div>
</footer>

</body>
</html>
